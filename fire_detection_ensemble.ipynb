{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fire Detection in Images\n\n**Description about the dataset:**\n\nData was collected to train a model to distinguish between the images that contain fire (fire images) and regular images (non-fire images). Data is divided into 2 folders, fireimages folder contains 755 outdoor-fire images some of them contains heavy smoke, the other one is non-fireimages which contain 244 nature images (eg: forest, tree, grass, river, people, foggy forest, lake, animal, road, and waterfall).\n\n**Objective: To create a classification model that can detect fire in images**\n\n**Models used: Sequential CNN from scratch, Pretrained Xception with modifications**","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\n\nsns.set_style('darkgrid')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:28.437874Z","iopub.execute_input":"2021-06-06T20:59:28.43825Z","iopub.status.idle":"2021-06-06T20:59:28.446923Z","shell.execute_reply.started":"2021-06-06T20:59:28.438219Z","shell.execute_reply":"2021-06-06T20:59:28.445813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's first create a dataframe that contains the path to each picture and its corresponding label (fire or non fire).**\n\n**Reading Paths**","metadata":{}},{"cell_type":"code","source":"#create an empty DataFrame\ndf = pd.DataFrame(columns=['path','label'])\n\n#loop over fire images and label them 1\nfor dirname, _, filenames in os.walk('/kaggle/input/fire-dataset/fire_dataset/fire_images'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        df = df.append(pd.DataFrame([[os.path.join(dirname, filename),'fire']],columns=['path','label']))\n\n#loop over non fire images and label them 0\nfor dirname, _, filenames in os.walk('/kaggle/input/fire-dataset/fire_dataset/non_fire_images'):\n    for filename in filenames:\n        df = df.append(pd.DataFrame([[os.path.join(dirname, filename),'non_fire']],columns=['path','label']))\n        #print(os.path.join(dirname, filename))\n\n#shuffle the dataset for redistribute the labels\ndf = df.sample(frac=1).reset_index(drop=True)\ndf.head(10)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T20:59:28.601758Z","iopub.execute_input":"2021-06-06T20:59:28.602135Z","iopub.status.idle":"2021-06-06T20:59:29.676391Z","shell.execute_reply.started":"2021-06-06T20:59:28.602103Z","shell.execute_reply":"2021-06-06T20:59:29.675389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Great! the dataset has been created. Let's see how well the data is shuffled.**","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(data_frame = df,x=df.index,y='label',color='label',title='Distribution of fire and non-fire images along the length of the dataframe')\nfig.update_traces(marker_size=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:29.677705Z","iopub.execute_input":"2021-06-06T20:59:29.677978Z","iopub.status.idle":"2021-06-06T20:59:29.76195Z","shell.execute_reply.started":"2021-06-06T20:59:29.677951Z","shell.execute_reply":"2021-06-06T20:59:29.760931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The shuffling has taken place well.**\n\n**Let's visualize the countplot of the data**","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"xy\"}, {\"type\": \"pie\"}]])\n\n\nfig.add_trace(go.Bar(x =df['label'].value_counts().index,y=df['label'].value_counts().to_numpy(),marker_color=['darkorange','green'],showlegend=False),row=1,col=1)\n\nfig.add_trace(go.Pie(\n     values=df['label'].value_counts().to_numpy(),\n     labels=df['label'].value_counts().index,\n    marker=dict(colors=['darkorange','green'])),\n    row=1, col=2)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:29.763776Z","iopub.execute_input":"2021-06-06T20:59:29.764064Z","iopub.status.idle":"2021-06-06T20:59:29.794879Z","shell.execute_reply.started":"2021-06-06T20:59:29.764037Z","shell.execute_reply":"2021-06-06T20:59:29.793964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Non fire label has less number of images. The dataset is imbalanced**","metadata":{}},{"cell_type":"markdown","source":"## Visualizing the images with fire","metadata":{}},{"cell_type":"code","source":"label = 'fire' #label for images with fire\ndata = df[df['label'] == label]\nsns.set_style('dark')\n\n\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics//2),2,figsize=(15,15))\nplt.suptitle('Images with Fire')\nax = ax.ravel()\nfor i in range((pics//2)*2):\n    path = data.sample(1).loc[:,'path'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:29.796549Z","iopub.execute_input":"2021-06-06T20:59:29.796858Z","iopub.status.idle":"2021-06-06T20:59:31.429886Z","shell.execute_reply.started":"2021-06-06T20:59:29.796827Z","shell.execute_reply":"2021-06-06T20:59:31.428564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = 'non_fire' #label for images without fire\ndata = df[df['label'] == label]\nsns.set_style('dark')\n\n\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics//2),2,figsize=(15,15))\nplt.suptitle('Images with Fire')\nax = ax.ravel()\nfor i in range((pics//2)*2):\n    path = data.sample(1).loc[:,'path'].to_numpy()[0]\n    img = image.load_img(path)\n    img = image.img_to_array(img)/255\n    ax[i].imshow(img)\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:31.431613Z","iopub.execute_input":"2021-06-06T20:59:31.431937Z","iopub.status.idle":"2021-06-06T20:59:32.907398Z","shell.execute_reply.started":"2021-06-06T20:59:31.431907Z","shell.execute_reply":"2021-06-06T20:59:32.906175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see, the sizes of the images are different. Let's visualize the distribution of their shapes**","metadata":{}},{"cell_type":"code","source":"def shaper(row):\n    shape = image.load_img(row['path']).size\n    row['height'] = shape[1]\n    row['width'] = shape[0]\n    return row\ndf = df.apply(shaper,axis=1)\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:32.909075Z","iopub.execute_input":"2021-06-06T20:59:32.909481Z","iopub.status.idle":"2021-06-06T20:59:36.48767Z","shell.execute_reply.started":"2021-06-06T20:59:32.909441Z","shell.execute_reply":"2021-06-06T20:59:36.486549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Shape Distribution","metadata":{}},{"cell_type":"code","source":"sns.set_style('darkgrid')\nfig,(ax1,ax2,ax3) = plt.subplots(1,3,gridspec_kw={'width_ratios': [3,0.5,0.5]},figsize=(15,10))\nsns.kdeplot(data=df.drop(columns=['path','label']),ax=ax1,legend=True)\nsns.boxplot(data=df,y='height',ax=ax2,color='skyblue')\nsns.boxplot(data=df,y='width',ax=ax3,color='orange')\nplt.suptitle('Distribution of image shapes')\nax3.set_ylim(0,7000)\nax2.set_ylim(0,7000)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:36.489272Z","iopub.execute_input":"2021-06-06T20:59:36.489712Z","iopub.status.idle":"2021-06-06T20:59:37.427846Z","shell.execute_reply.started":"2021-06-06T20:59:36.489654Z","shell.execute_reply":"2021-06-06T20:59:37.426588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The height and width of images vary too much. We have to reshape them to a fixed shape before training**\n\n## Image Generation or Augmentation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:37.430187Z","iopub.execute_input":"2021-06-06T20:59:37.430501Z","iopub.status.idle":"2021-06-06T20:59:37.434929Z","shell.execute_reply.started":"2021-06-06T20:59:37.430469Z","shell.execute_reply":"2021-06-06T20:59:37.433786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = ImageDataGenerator(\n    rotation_range= 20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range = 2,\n    zoom_range=0.2,\n    rescale = 1/255,\n    validation_split=0.2,\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:37.437385Z","iopub.execute_input":"2021-06-06T20:59:37.437887Z","iopub.status.idle":"2021-06-06T20:59:37.450749Z","shell.execute_reply.started":"2021-06-06T20:59:37.437841Z","shell.execute_reply":"2021-06-06T20:59:37.449488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating the training and test generator**\n\n**We will use the flow_from_dataframe method of the ImageDataGenerator class. It will take the path of the images from the dataframe along with their labels. We construct two generators, one for training and the other for validation.**\n\n**Note: Our labels are strings 'fire ' and 'non_fire'. Image generator will automatically encode them to integer labels.**","metadata":{}},{"cell_type":"code","source":"train_gen = generator.flow_from_dataframe(df,x_col='path',y_col='label',images_size=(256,256),class_mode='binary',subset='training')\nval_gen = generator.flow_from_dataframe(df,x_col='path',y_col='label',images_size=(256,256),class_mode='binary',subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:37.452304Z","iopub.execute_input":"2021-06-06T20:59:37.452865Z","iopub.status.idle":"2021-06-06T20:59:37.501083Z","shell.execute_reply.started":"2021-06-06T20:59:37.452812Z","shell.execute_reply":"2021-06-06T20:59:37.500112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Class indices assigned by the Image generator","metadata":{}},{"cell_type":"code","source":"class_indices = {}\nfor key in train_gen.class_indices.keys():\n    class_indices[train_gen.class_indices[key]] = key\n    \nprint(class_indices)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:37.502581Z","iopub.execute_input":"2021-06-06T20:59:37.502884Z","iopub.status.idle":"2021-06-06T20:59:37.509093Z","shell.execute_reply.started":"2021-06-06T20:59:37.502852Z","shell.execute_reply":"2021-06-06T20:59:37.507881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hence an image predicted 0 will contain fire and 1 won't.**","metadata":{}},{"cell_type":"markdown","source":"## Visualizing the generated images in training set","metadata":{}},{"cell_type":"code","source":"sns.set_style('dark')\npics = 6 #set the number of pics\nfig,ax = plt.subplots(int(pics//2),2,figsize=(15,15))\nplt.suptitle('Generated images in training set')\nax = ax.ravel()\nfor i in range((pics//2)*2):\n    ax[i].imshow(train_gen[0][0][i])\n    ax[i].axes.xaxis.set_visible(False)\n    ax[i].axes.yaxis.set_visible(False)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:37.510675Z","iopub.execute_input":"2021-06-06T20:59:37.510981Z","iopub.status.idle":"2021-06-06T20:59:49.449246Z","shell.execute_reply.started":"2021-06-06T20:59:37.51095Z","shell.execute_reply":"2021-06-06T20:59:49.448212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:49.450635Z","iopub.execute_input":"2021-06-06T20:59:49.450945Z","iopub.status.idle":"2021-06-06T20:59:49.455635Z","shell.execute_reply.started":"2021-06-06T20:59:49.450913Z","shell.execute_reply":"2021-06-06T20:59:49.454765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters=32,kernel_size = (2,2),activation='relu',input_shape = (256,256,3)))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(filters=64,kernel_size=(2,2),activation='relu'))\nmodel.add(MaxPool2D())\nmodel.add(Conv2D(filters=128,kernel_size=(2,2),activation='relu'))\nmodel.add(MaxPool2D())\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(32,activation = 'relu'))\nmodel.add(Dense(1,activation = 'sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:49.456945Z","iopub.execute_input":"2021-06-06T20:59:49.457512Z","iopub.status.idle":"2021-06-06T20:59:49.606719Z","shell.execute_reply.started":"2021-06-06T20:59:49.457467Z","shell.execute_reply":"2021-06-06T20:59:49.605825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We increase the number of filters as we add more layers because initially there will be a lot of noise present in the input and we only need to capture the important information. Later as we progress through the layers, the feature maps become nuanced and we try to capture them with more filters**  ","metadata":{}},{"cell_type":"markdown","source":"### Model Summary","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:49.607783Z","iopub.execute_input":"2021-06-06T20:59:49.608207Z","iopub.status.idle":"2021-06-06T20:59:49.618171Z","shell.execute_reply.started":"2021-06-06T20:59:49.608166Z","shell.execute_reply":"2021-06-06T20:59:49.617109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compiling the model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.metrics import Recall,AUC\nfrom tensorflow.keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:49.619953Z","iopub.execute_input":"2021-06-06T20:59:49.620269Z","iopub.status.idle":"2021-06-06T20:59:49.625844Z","shell.execute_reply.started":"2021-06-06T20:59:49.620228Z","shell.execute_reply":"2021-06-06T20:59:49.624868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy',Recall(),AUC()])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:49.627079Z","iopub.execute_input":"2021-06-06T20:59:49.627522Z","iopub.status.idle":"2021-06-06T20:59:49.662614Z","shell.execute_reply.started":"2021-06-06T20:59:49.627479Z","shell.execute_reply":"2021-06-06T20:59:49.661544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining Callbacks**\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:49.663949Z","iopub.execute_input":"2021-06-06T20:59:49.664254Z","iopub.status.idle":"2021-06-06T20:59:49.668448Z","shell.execute_reply.started":"2021-06-06T20:59:49.664222Z","shell.execute_reply":"2021-06-06T20:59:49.667453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stoppping = EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\nreduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=5)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:59:49.6698Z","iopub.execute_input":"2021-06-06T20:59:49.670163Z","iopub.status.idle":"2021-06-06T20:59:49.683153Z","shell.execute_reply.started":"2021-06-06T20:59:49.67013Z","shell.execute_reply":"2021-06-06T20:59:49.682199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Fitting","metadata":{}},{"cell_type":"code","source":"model.fit(x=train_gen,batch_size=32,epochs=15,validation_data=val_gen,callbacks=[early_stoppping,reduce_lr_on_plateau])","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-06T20:59:49.684744Z","iopub.execute_input":"2021-06-06T20:59:49.685058Z","iopub.status.idle":"2021-06-06T21:01:02.621905Z","shell.execute_reply.started":"2021-06-06T20:59:49.685027Z","shell.execute_reply":"2021-06-06T21:01:02.620898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation\n\n**Plotting metrics**","metadata":{}},{"cell_type":"code","source":"history= model.history.history\npx.line(history,title = \"Metrics Plot\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:01:02.623408Z","iopub.execute_input":"2021-06-06T21:01:02.623797Z","iopub.status.idle":"2021-06-06T21:01:02.740467Z","shell.execute_reply.started":"2021-06-06T21:01:02.623759Z","shell.execute_reply":"2021-06-06T21:01:02.739214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_list = model.evaluate(val_gen,return_dict=True)\nfor metric in eval_list.keys():\n    print(metric+f\": {eval_list[metric]:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:01:02.741826Z","iopub.execute_input":"2021-06-06T21:01:02.74214Z","iopub.status.idle":"2021-06-06T21:01:16.934143Z","shell.execute_reply.started":"2021-06-06T21:01:02.742106Z","shell.execute_reply":"2021-06-06T21:01:16.933085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model creation by transfer learning","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:01:16.93768Z","iopub.execute_input":"2021-06-06T21:01:16.937983Z","iopub.status.idle":"2021-06-06T21:01:16.942182Z","shell.execute_reply.started":"2021-06-06T21:01:16.937953Z","shell.execute_reply":"2021-06-06T21:01:16.941459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception = Xception(include_top = False,input_shape = (256,256,3))\ninput_to_model = xception.input\n#turn off training\nxception.trainable = False\n\nx = Flatten()(xception.output)\nx = Dense(64,activation = 'relu')(x)\noutput_to_model = Dense(1,activation = 'sigmoid')(x)\nmodel2 = Model(inputs = input_to_model,outputs = output_to_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:01:16.943919Z","iopub.execute_input":"2021-06-06T21:01:16.944491Z","iopub.status.idle":"2021-06-06T21:01:18.449028Z","shell.execute_reply.started":"2021-06-06T21:01:16.944449Z","shell.execute_reply":"2021-06-06T21:01:18.447975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compiling the model**","metadata":{}},{"cell_type":"code","source":"model2.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy',Recall(),AUC()])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:01:18.450158Z","iopub.execute_input":"2021-06-06T21:01:18.450477Z","iopub.status.idle":"2021-06-06T21:01:18.478816Z","shell.execute_reply.started":"2021-06-06T21:01:18.450445Z","shell.execute_reply":"2021-06-06T21:01:18.477662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting the model**","metadata":{}},{"cell_type":"code","source":"history2 = model2.fit(x = train_gen,batch_size=32,epochs=15,callbacks = [early_stoppping,reduce_lr_on_plateau],validation_data = val_gen)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-06T21:01:18.480145Z","iopub.execute_input":"2021-06-06T21:01:18.480527Z","iopub.status.idle":"2021-06-06T21:04:16.715002Z","shell.execute_reply.started":"2021-06-06T21:01:18.48049Z","shell.execute_reply":"2021-06-06T21:04:16.713982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{}},{"cell_type":"code","source":"px.line(history,title='Metrics Plot')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:04:16.716473Z","iopub.execute_input":"2021-06-06T21:04:16.716765Z","iopub.status.idle":"2021-06-06T21:04:16.836185Z","shell.execute_reply.started":"2021-06-06T21:04:16.716737Z","shell.execute_reply":"2021-06-06T21:04:16.835178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_list = model.evaluate(val_gen,return_dict=True)\nfor metric in eval_list.keys():\n    print(metric+f\": {eval_list[metric]:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:04:16.837703Z","iopub.execute_input":"2021-06-06T21:04:16.83813Z","iopub.status.idle":"2021-06-06T21:04:31.628493Z","shell.execute_reply.started":"2021-06-06T21:04:16.838083Z","shell.execute_reply":"2021-06-06T21:04:31.627396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Example Prediction\n\n**Let's use an image of the apartment complex in Texas that caught fire in February 2021.**\n\nNews link : https://www.nytimes.com/2021/02/19/us/san-antonio-fire-hydrants-water.html","metadata":{}},{"cell_type":"code","source":"#Downloading the image\n!curl https://static01.nyt.com/images/2021/02/19/world/19storm-briefing-texas-fire/19storm-briefing-texas-fire-articleLarge.jpg --output predict.jpg","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:04:31.629805Z","iopub.execute_input":"2021-06-06T21:04:31.630137Z","iopub.status.idle":"2021-06-06T21:04:33.578752Z","shell.execute_reply.started":"2021-06-06T21:04:31.630101Z","shell.execute_reply":"2021-06-06T21:04:33.577798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Printing the image**","metadata":{}},{"cell_type":"code","source":"#loading the image\nimg = image.load_img('predict.jpg')\nimg","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:04:33.580367Z","iopub.execute_input":"2021-06-06T21:04:33.580701Z","iopub.status.idle":"2021-06-06T21:04:33.756155Z","shell.execute_reply.started":"2021-06-06T21:04:33.580667Z","shell.execute_reply":"2021-06-06T21:04:33.755142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Resizing the image and expanding its dimension to include the batch size - 1**","metadata":{}},{"cell_type":"code","source":"img = image.img_to_array(img)/255\nimg = tf.image.resize(img,(256,256))\nimg = tf.expand_dims(img,axis=0)\n\nprint(\"Image Shape\",img.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:04:33.757524Z","iopub.execute_input":"2021-06-06T21:04:33.757846Z","iopub.status.idle":"2021-06-06T21:04:33.768954Z","shell.execute_reply.started":"2021-06-06T21:04:33.757805Z","shell.execute_reply":"2021-06-06T21:04:33.767868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prediction**","metadata":{}},{"cell_type":"code","source":"prediction = int(tf.round(model2.predict(x=img)).numpy()[0][0])\nprint(\"The predicted value is: \",prediction,\"and the predicted label is:\",class_indices[prediction])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T21:04:33.771187Z","iopub.execute_input":"2021-06-06T21:04:33.771765Z","iopub.status.idle":"2021-06-06T21:04:34.73915Z","shell.execute_reply.started":"2021-06-06T21:04:33.7717Z","shell.execute_reply":"2021-06-06T21:04:34.738424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thank You","metadata":{}}]}